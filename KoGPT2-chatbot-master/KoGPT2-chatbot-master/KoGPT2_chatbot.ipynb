{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "sOqL-ERxwMDz",
    "outputId": "2dd69db1-6c9d-4bd8-f044-393656c00a70"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "# GPU 정보 \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "rUbPw_7Bf9Jr",
    "outputId": "fe8dc0dc-32ee-4cc1-90e2-6f521707e629"
   },
   "outputs": [],
   "source": [
    "# 현재 CUDA 10.1이라 mxnet-cu101로 설치\n",
    "# CUDA에 맞는 mxnet 버전을 선택해야함 (https://mxnet.apache.org/get_started 참조)\n",
    "# 만약 GPU 사용을 하고 있지 않다는 문구가 뜬다면 올바른 버전이 아님\n",
    "!pip install mxnet-cu101"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "4WKGlGahhDAL",
    "outputId": "ef5b51f2-bff8-4090-cfa1-f0228124fb60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gluonnlp in /usr/local/lib/python3.6/dist-packages (0.9.1)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (0.1.91)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.5)\n",
      "Requirement already satisfied: cython in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (0.29.20)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (20.4)\n",
      "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from gluonnlp) (1.18.5)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (1.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->gluonnlp) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "# 패키지 설치\n",
    "!pip install gluonnlp sentencepiece pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "pc9gWX3SkP6G",
    "outputId": "9a4236e2-4bb2-4328-92e7-404ce622f02b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kogpt2 from git+https://github.com/SKT-AI/KoGPT2#egg=kogpt2 in /usr/local/lib/python3.6/dist-packages (0.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SKT-AI/KoGPT2#egg=kogpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "P8W3gZk2ijYN",
    "outputId": "0b29cd05-704c-4bfd-932c-61bd506ea96f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoGPT2-chatbot'...\n",
      "remote: Enumerating objects: 33, done.\u001b[K\n",
      "remote: Counting objects:   3% (1/33)\u001b[K\r",
      "remote: Counting objects:   6% (2/33)\u001b[K\r",
      "remote: Counting objects:   9% (3/33)\u001b[K\r",
      "remote: Counting objects:  12% (4/33)\u001b[K\r",
      "remote: Counting objects:  15% (5/33)\u001b[K\r",
      "remote: Counting objects:  18% (6/33)\u001b[K\r",
      "remote: Counting objects:  21% (7/33)\u001b[K\r",
      "remote: Counting objects:  24% (8/33)\u001b[K\r",
      "remote: Counting objects:  27% (9/33)\u001b[K\r",
      "remote: Counting objects:  30% (10/33)\u001b[K\r",
      "remote: Counting objects:  33% (11/33)\u001b[K\r",
      "remote: Counting objects:  36% (12/33)\u001b[K\r",
      "remote: Counting objects:  39% (13/33)\u001b[K\r",
      "remote: Counting objects:  42% (14/33)\u001b[K\r",
      "remote: Counting objects:  45% (15/33)\u001b[K\r",
      "remote: Counting objects:  48% (16/33)\u001b[K\r",
      "remote: Counting objects:  51% (17/33)\u001b[K\r",
      "remote: Counting objects:  54% (18/33)\u001b[K\r",
      "remote: Counting objects:  57% (19/33)\u001b[K\r",
      "remote: Counting objects:  60% (20/33)\u001b[K\r",
      "remote: Counting objects:  63% (21/33)\u001b[K\r",
      "remote: Counting objects:  66% (22/33)\u001b[K\r",
      "remote: Counting objects:  69% (23/33)\u001b[K\r",
      "remote: Counting objects:  72% (24/33)\u001b[K\r",
      "remote: Counting objects:  75% (25/33)\u001b[K\r",
      "remote: Counting objects:  78% (26/33)\u001b[K\r",
      "remote: Counting objects:  81% (27/33)\u001b[K\r",
      "remote: Counting objects:  84% (28/33)\u001b[K\r",
      "remote: Counting objects:  87% (29/33)\u001b[K\r",
      "remote: Counting objects:  90% (30/33)\u001b[K\r",
      "remote: Counting objects:  93% (31/33)\u001b[K\r",
      "remote: Counting objects:  96% (32/33)\u001b[K\r",
      "remote: Counting objects: 100% (33/33)\u001b[K\r",
      "remote: Counting objects: 100% (33/33), done.\u001b[K\n",
      "remote: Compressing objects:   4% (1/24)\u001b[K\r",
      "remote: Compressing objects:   8% (2/24)\u001b[K\r",
      "remote: Compressing objects:  12% (3/24)\u001b[K\r",
      "remote: Compressing objects:  16% (4/24)\u001b[K\r",
      "remote: Compressing objects:  20% (5/24)\u001b[K\r",
      "remote: Compressing objects:  25% (6/24)\u001b[K\r",
      "remote: Compressing objects:  29% (7/24)\u001b[K\r",
      "remote: Compressing objects:  33% (8/24)\u001b[K\r",
      "remote: Compressing objects:  37% (9/24)\u001b[K\r",
      "remote: Compressing objects:  41% (10/24)\u001b[K\r",
      "remote: Compressing objects:  45% (11/24)\u001b[K\r",
      "remote: Compressing objects:  50% (12/24)\u001b[K\r",
      "remote: Compressing objects:  54% (13/24)\u001b[K\r",
      "remote: Compressing objects:  58% (14/24)\u001b[K\r",
      "remote: Compressing objects:  62% (15/24)\u001b[K\r",
      "remote: Compressing objects:  66% (16/24)\u001b[K\r",
      "remote: Compressing objects:  70% (17/24)\u001b[K\r",
      "remote: Compressing objects:  75% (18/24)\u001b[K\r",
      "remote: Compressing objects:  79% (19/24)\u001b[K\r",
      "remote: Compressing objects:  83% (20/24)\u001b[K\r",
      "remote: Compressing objects:  87% (21/24)\u001b[K\r",
      "remote: Compressing objects:  91% (22/24)\u001b[K\r",
      "remote: Compressing objects:  95% (23/24)\u001b[K\r",
      "remote: Compressing objects: 100% (24/24)\u001b[K\r",
      "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
      "Unpacking objects:   3% (1/33)   \r",
      "Unpacking objects:   6% (2/33)   \r",
      "Unpacking objects:   9% (3/33)   \r",
      "Unpacking objects:  12% (4/33)   \r",
      "Unpacking objects:  15% (5/33)   \r",
      "Unpacking objects:  18% (6/33)   \r",
      "Unpacking objects:  21% (7/33)   \r",
      "Unpacking objects:  24% (8/33)   \r",
      "Unpacking objects:  27% (9/33)   \r",
      "Unpacking objects:  30% (10/33)   \r",
      "Unpacking objects:  33% (11/33)   \r",
      "Unpacking objects:  36% (12/33)   \r",
      "Unpacking objects:  39% (13/33)   \r",
      "Unpacking objects:  42% (14/33)   \r",
      "Unpacking objects:  45% (15/33)   \r",
      "remote: Total 33 (delta 11), reused 21 (delta 6), pack-reused 0\u001b[K\n",
      "Unpacking objects:  48% (16/33)   \r",
      "Unpacking objects:  51% (17/33)   \r",
      "Unpacking objects:  54% (18/33)   \r",
      "Unpacking objects:  57% (19/33)   \r",
      "Unpacking objects:  60% (20/33)   \r",
      "Unpacking objects:  63% (21/33)   \r",
      "Unpacking objects:  66% (22/33)   \r",
      "Unpacking objects:  69% (23/33)   \r",
      "Unpacking objects:  72% (24/33)   \r",
      "Unpacking objects:  75% (25/33)   \r",
      "Unpacking objects:  78% (26/33)   \r",
      "Unpacking objects:  81% (27/33)   \r",
      "Unpacking objects:  84% (28/33)   \r",
      "Unpacking objects:  87% (29/33)   \r",
      "Unpacking objects:  90% (30/33)   \r",
      "Unpacking objects:  93% (31/33)   \r",
      "Unpacking objects:  96% (32/33)   \r",
      "Unpacking objects: 100% (33/33)   \r",
      "Unpacking objects: 100% (33/33), done.\n",
      "Submodule 'Chatbot_data' (https://github.com/haven-jeon/Chatbot_data.git) registered for path 'Chatbot_data'\n",
      "Cloning into '/content/KoGPT2-chatbot/Chatbot_data'...\n",
      "remote: Enumerating objects: 20, done.        \n",
      "remote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20        \n",
      "Submodule path 'Chatbot_data': checked out '235fac5aea3badab22743f7048afe936cf72f822'\n"
     ]
    }
   ],
   "source": [
    "# KoGPT2-chatbot 복사\n",
    "!git clone --recurse-submodules https://github.com/haven-jeon/KoGPT2-chatbot.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e9ZweKmXiuaK",
    "outputId": "57d2b3f3-ac0f-45d7-f4da-c95d1a5ff21e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/KoGPT2-chatbot\n"
     ]
    }
   ],
   "source": [
    "# 폴더 이동\n",
    "%cd KoGPT2-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 662
    },
    "colab_type": "code",
    "id": "xKMZv-ZsiqkB",
    "outputId": "c9ef9c22-f4e8-43e4-99ae-069509724e5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[██████████████████████████████████████████████████]\n",
      "[██████████████████████████████████████████████████]\n",
      "using cached model\n",
      "INFO:root:contexts : 오늘이 생일이네\n",
      "INFO:root:toked ctx: ['<usr>', '▁오늘', '이', '▁생', '일이', '네', '</s>', '<unused1>', '▁1', '</s>']\n",
      "INFO:root:response : 기억에서 지울 순 없지만 최대한 생각 말아보셔요.\n",
      "INFO:root:toked response : ['<sys>', '▁기억', '에서', '▁지', '울', '▁순', '▁없지만', '▁최대한', '▁생각', '▁말아', '보', '셔', '요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁기억', '에서', '▁지', '울', '▁순', '▁없지만', '▁최대한', '▁생각', '▁말아', '보', '셔', '요', '.', '</s>']\n",
      "INFO:root:contexts : 재회를 위한 기다림\n",
      "INFO:root:toked ctx: ['<usr>', '▁재', '회를', '▁위한', '▁기다', '림', '</s>', '<unused1>', '▁1', '</s>']\n",
      "INFO:root:response : 가만히 있는다고 달라지는 건 없을 거예요.\n",
      "INFO:root:toked response : ['<sys>', '▁가만히', '▁있는', '다고', '▁달라지는', '▁건', '▁없을', '▁거예요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁가만히', '▁있는', '다고', '▁달라지는', '▁건', '▁없을', '▁거예요', '.', '</s>']\n",
      "INFO:root:contexts : 8년 사귀고 헤어진지 2달\n",
      "INFO:root:toked ctx: ['<usr>', '▁8', '년', '▁사귀', '고', '▁헤어진', '지', '▁2', '달', '</s>', '<unused1>', '▁1', '</s>']\n",
      "INFO:root:response : 딱 힘들 때네요.\n",
      "INFO:root:toked response : ['<sys>', '▁딱', '▁힘들', '▁때', '네요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁딱', '▁힘들', '▁때', '네요', '.', '</s>']\n",
      "INFO:root:contexts : 핸드폰게임 자꾸 하게돼\n",
      "INFO:root:toked ctx: ['<usr>', '▁핸드폰', '게임', '▁자꾸', '▁하게', '돼', '</s>', '<unused1>', '▁0', '</s>']\n",
      "INFO:root:response : 시간을 정해보세요.\n",
      "INFO:root:toked response : ['<sys>', '▁시간을', '▁정해', '보세요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁시간을', '▁정해', '보세요', '.', '</s>']\n",
      "INFO:root:contexts : 관계가 계속 애매하다.\n",
      "INFO:root:toked ctx: ['<usr>', '▁관계가', '▁계속', '▁애매', '하다', '.', '</s>', '<unused1>', '▁0', '</s>']\n",
      "INFO:root:response : 인간 관계도 정리가 필요해요.\n",
      "INFO:root:toked response : ['<sys>', '▁인간', '▁관계', '도', '▁정', '리가', '▁필요', '해요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁인간', '▁관계', '도', '▁정', '리가', '▁필요', '해요', '.', '</s>']\n",
      "[Epoch 1 Batch 50/185] loss=1.0495, lr=0.0000480480, train ppl=2.856\n",
      "[Epoch 1 Batch 100/185] loss=0.9733, lr=0.0000405405, train ppl=2.647\n",
      "[Epoch 1 Batch 150/185] loss=0.9670, lr=0.0000330330, train ppl=2.630\n",
      "[Epoch 2 Batch 15/185] loss=0.2846, lr=0.0000255255, train ppl=1.329\n",
      "[Epoch 2 Batch 65/185] loss=0.9485, lr=0.0000180180, train ppl=2.582\n",
      "[Epoch 2 Batch 115/185] loss=0.9515, lr=0.0000105105, train ppl=2.589\n",
      "[Epoch 2 Batch 165/185] loss=0.9573, lr=0.0000030030, train ppl=2.605\n",
      "INFO:root:saving model file to kogpt2_chat.params\n"
     ]
    }
   ],
   "source": [
    "# 사전훈련된 KoGPT2를 챗봇 데이터로 파인튜닝\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py --num-epoch 2 --train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "f3yDcidi6wFA",
    "outputId": "3295c36b-16c1-42e6-9333-2bc21058f4d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "user > 어버이날에는 뭐 하지?\n",
      "Simsimi > 부모님께 효도하는거요.\n",
      "user > 아 더워 미치겠음..\n",
      "Simsimi > 시원한 물 한 잔 드세요.\n",
      "user > quit\n"
     ]
    }
   ],
   "source": [
    "# 대화 테스트, `quit`를 입력하면 대화를 종료합니다.\n",
    "!CUDA_VISIBLE_DEVICES=0 python train.py --chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoeGog7OoXFk"
   },
   "source": [
    "이 노트북은   https://colab.research.google.com/drive/1Np7d8zrch589LwwW9oX_MyzJ9jfPEvUG?usp=sharing  를 수정하여 만들었습니다..  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KoGPT2_chatbot.ipynb의 사본",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
