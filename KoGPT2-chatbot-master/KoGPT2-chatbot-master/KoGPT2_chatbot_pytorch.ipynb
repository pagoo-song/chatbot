{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "sOqL-ERxwMDz",
    "outputId": "736237e4-5772-4a0a-d628-eca21a883317"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi'은(는) 내부 또는 외부 명령, 실행할 수 있는 프로그램, 또는\n",
      "배치 파일이 아닙니다.\n"
     ]
    }
   ],
   "source": [
    "# GPU 정보 \n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 121
    },
    "colab_type": "code",
    "id": "rUbPw_7Bf9Jr",
    "outputId": "7dcd19a4-b6ed-4bb1-f844-7d2e419abf50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
      "Collecting torch==1.5.1+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-win_amd64.whl (858.4 MB)\n",
      "Collecting torchvision==0.6.1+cu101\n",
      "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-win_amd64.whl (1.2 MB)\n",
      "Requirement already satisfied: numpy in c:\\users\\xnote\\anaconda3\\lib\\site-packages (from torch==1.5.1+cu101) (1.16.6)\n",
      "Requirement already satisfied: future in c:\\users\\xnote\\anaconda3\\lib\\site-packages (from torch==1.5.1+cu101) (0.17.1)\n",
      "Requirement already satisfied: pillow>=4.1.1 in c:\\users\\xnote\\anaconda3\\lib\\site-packages (from torchvision==0.6.1+cu101) (6.2.0)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.3.1\n",
      "    Uninstalling torch-1.3.1:\n",
      "      Successfully uninstalled torch-1.3.1\n",
      "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n"
     ]
    }
   ],
   "source": [
    "# 현재 CUDA Version에 맞는 Pytorch 설치\n",
    "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "4WKGlGahhDAL",
    "outputId": "306c7476-a021-48f0-ce0b-c3a85bffd2a4"
   },
   "outputs": [],
   "source": [
    "# 패키지 설치\n",
    "!pip install mxnet gluonnlp sentencepiece pandas transformers pytorch_lightning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 191
    },
    "colab_type": "code",
    "id": "pc9gWX3SkP6G",
    "outputId": "b79d143d-908a-4914-b47d-bd0f4a3cfa86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kogpt2\n",
      "  Cloning https://github.com/SKT-AI/KoGPT2 to /tmp/pip-install-lmf90hij/kogpt2\n",
      "  Running command git clone -q https://github.com/SKT-AI/KoGPT2 /tmp/pip-install-lmf90hij/kogpt2\n",
      "Building wheels for collected packages: kogpt2\n",
      "  Building wheel for kogpt2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for kogpt2: filename=kogpt2-0.1.1-cp36-none-any.whl size=14052 sha256=241778ebcd2f58850e8278397b4d0132116b43e1deb6eb5691021367647a3e25\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-os9az673/wheels/2a/9f/62/3cba71a35387ff5da1d12e6b053b4d839dab0ed4310dde840d\n",
      "Successfully built kogpt2\n",
      "Installing collected packages: kogpt2\n",
      "Successfully installed kogpt2-0.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install git+https://github.com/SKT-AI/KoGPT2#egg=kogpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "P8W3gZk2ijYN",
    "outputId": "bc4ee445-1bf3-4af2-c433-375634918c7c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'KoGPT2-chatbot'...\n",
      "remote: Enumerating objects: 62, done.\u001b[K\n",
      "remote: Counting objects:   1% (1/62)\u001b[K\r",
      "remote: Counting objects:   3% (2/62)\u001b[K\r",
      "remote: Counting objects:   4% (3/62)\u001b[K\r",
      "remote: Counting objects:   6% (4/62)\u001b[K\r",
      "remote: Counting objects:   8% (5/62)\u001b[K\r",
      "remote: Counting objects:   9% (6/62)\u001b[K\r",
      "remote: Counting objects:  11% (7/62)\u001b[K\r",
      "remote: Counting objects:  12% (8/62)\u001b[K\r",
      "remote: Counting objects:  14% (9/62)\u001b[K\r",
      "remote: Counting objects:  16% (10/62)\u001b[K\r",
      "remote: Counting objects:  17% (11/62)\u001b[K\r",
      "remote: Counting objects:  19% (12/62)\u001b[K\r",
      "remote: Counting objects:  20% (13/62)\u001b[K\r",
      "remote: Counting objects:  22% (14/62)\u001b[K\r",
      "remote: Counting objects:  24% (15/62)\u001b[K\r",
      "remote: Counting objects:  25% (16/62)\u001b[K\r",
      "remote: Counting objects:  27% (17/62)\u001b[K\r",
      "remote: Counting objects:  29% (18/62)\u001b[K\r",
      "remote: Counting objects:  30% (19/62)\u001b[K\r",
      "remote: Counting objects:  32% (20/62)\u001b[K\r",
      "remote: Counting objects:  33% (21/62)\u001b[K\r",
      "remote: Counting objects:  35% (22/62)\u001b[K\r",
      "remote: Counting objects:  37% (23/62)\u001b[K\r",
      "remote: Counting objects:  38% (24/62)\u001b[K\r",
      "remote: Counting objects:  40% (25/62)\u001b[K\r",
      "remote: Counting objects:  41% (26/62)\u001b[K\r",
      "remote: Counting objects:  43% (27/62)\u001b[K\r",
      "remote: Counting objects:  45% (28/62)\u001b[K\r",
      "remote: Counting objects:  46% (29/62)\u001b[K\r",
      "remote: Counting objects:  48% (30/62)\u001b[K\r",
      "remote: Counting objects:  50% (31/62)\u001b[K\r",
      "remote: Counting objects:  51% (32/62)\u001b[K\r",
      "remote: Counting objects:  53% (33/62)\u001b[K\r",
      "remote: Counting objects:  54% (34/62)\u001b[K\r",
      "remote: Counting objects:  56% (35/62)\u001b[K\r",
      "remote: Counting objects:  58% (36/62)\u001b[K\r",
      "remote: Counting objects:  59% (37/62)\u001b[K\r",
      "remote: Counting objects:  61% (38/62)\u001b[K\r",
      "remote: Counting objects:  62% (39/62)\u001b[K\r",
      "remote: Counting objects:  64% (40/62)\u001b[K\r",
      "remote: Counting objects:  66% (41/62)\u001b[K\r",
      "remote: Counting objects:  67% (42/62)\u001b[K\r",
      "remote: Counting objects:  69% (43/62)\u001b[K\r",
      "remote: Counting objects:  70% (44/62)\u001b[K\r",
      "remote: Counting objects:  72% (45/62)\u001b[K\r",
      "remote: Counting objects:  74% (46/62)\u001b[K\r",
      "remote: Counting objects:  75% (47/62)\u001b[K\r",
      "remote: Counting objects:  77% (48/62)\u001b[K\r",
      "remote: Counting objects:  79% (49/62)\u001b[K\r",
      "remote: Counting objects:  80% (50/62)\u001b[K\r",
      "remote: Counting objects:  82% (51/62)\u001b[K\r",
      "remote: Counting objects:  83% (52/62)\u001b[K\r",
      "remote: Counting objects:  85% (53/62)\u001b[K\r",
      "remote: Counting objects:  87% (54/62)\u001b[K\r",
      "remote: Counting objects:  88% (55/62)\u001b[K\r",
      "remote: Counting objects:  90% (56/62)\u001b[K\r",
      "remote: Counting objects:  91% (57/62)\u001b[K\r",
      "remote: Counting objects:  93% (58/62)\u001b[K\r",
      "remote: Counting objects:  95% (59/62)\u001b[K\r",
      "remote: Counting objects:  96% (60/62)\u001b[K\r",
      "remote: Counting objects:  98% (61/62)\u001b[K\r",
      "remote: Counting objects: 100% (62/62)\u001b[K\r",
      "remote: Counting objects: 100% (62/62), done.\u001b[K\n",
      "remote: Compressing objects:   2% (1/44)\u001b[K\r",
      "remote: Compressing objects:   4% (2/44)\u001b[K\r",
      "remote: Compressing objects:   6% (3/44)\u001b[K\r",
      "remote: Compressing objects:   9% (4/44)\u001b[K\r",
      "remote: Compressing objects:  11% (5/44)\u001b[K\r",
      "remote: Compressing objects:  13% (6/44)\u001b[K\r",
      "remote: Compressing objects:  15% (7/44)\u001b[K\r",
      "remote: Compressing objects:  18% (8/44)\u001b[K\r",
      "remote: Compressing objects:  20% (9/44)\u001b[K\r",
      "remote: Compressing objects:  22% (10/44)\u001b[K\r",
      "remote: Compressing objects:  25% (11/44)\u001b[K\r",
      "remote: Compressing objects:  27% (12/44)\u001b[K\r",
      "remote: Compressing objects:  29% (13/44)\u001b[K\r",
      "remote: Compressing objects:  31% (14/44)\u001b[K\r",
      "remote: Compressing objects:  34% (15/44)\u001b[K\r",
      "remote: Compressing objects:  36% (16/44)\u001b[K\r",
      "remote: Compressing objects:  38% (17/44)\u001b[K\r",
      "remote: Compressing objects:  40% (18/44)\u001b[K\r",
      "remote: Compressing objects:  43% (19/44)\u001b[K\r",
      "remote: Compressing objects:  45% (20/44)\u001b[K\r",
      "remote: Compressing objects:  47% (21/44)\u001b[K\r",
      "remote: Compressing objects:  50% (22/44)\u001b[K\r",
      "remote: Compressing objects:  52% (23/44)\u001b[K\r",
      "remote: Compressing objects:  54% (24/44)\u001b[K\r",
      "remote: Compressing objects:  56% (25/44)\u001b[K\r",
      "remote: Compressing objects:  59% (26/44)\u001b[K\r",
      "remote: Compressing objects:  61% (27/44)\u001b[K\r",
      "remote: Compressing objects:  63% (28/44)\u001b[K\r",
      "remote: Compressing objects:  65% (29/44)\u001b[K\r",
      "remote: Compressing objects:  68% (30/44)\u001b[K\r",
      "remote: Compressing objects:  70% (31/44)\u001b[K\r",
      "remote: Compressing objects:  72% (32/44)\u001b[K\r",
      "remote: Compressing objects:  75% (33/44)\u001b[K\r",
      "remote: Compressing objects:  77% (34/44)\u001b[K\r",
      "remote: Compressing objects:  79% (35/44)\u001b[K\r",
      "remote: Compressing objects:  81% (36/44)\u001b[K\r",
      "remote: Compressing objects:  84% (37/44)\u001b[K\r",
      "remote: Compressing objects:  86% (38/44)\u001b[K\r",
      "remote: Compressing objects:  88% (39/44)\u001b[K\r",
      "remote: Compressing objects:  90% (40/44)\u001b[K\r",
      "remote: Compressing objects:  93% (41/44)\u001b[K\r",
      "remote: Compressing objects:  95% (42/44)\u001b[K\r",
      "remote: Compressing objects:  97% (43/44)\u001b[K\r",
      "remote: Compressing objects: 100% (44/44)\u001b[K\r",
      "remote: Compressing objects: 100% (44/44), done.\u001b[K\n",
      "Unpacking objects:   1% (1/62)   \r",
      "Unpacking objects:   3% (2/62)   \r",
      "Unpacking objects:   4% (3/62)   \r",
      "Unpacking objects:   6% (4/62)   \r",
      "Unpacking objects:   8% (5/62)   \r",
      "Unpacking objects:   9% (6/62)   \r",
      "Unpacking objects:  11% (7/62)   \r",
      "Unpacking objects:  12% (8/62)   \r",
      "Unpacking objects:  14% (9/62)   \r",
      "Unpacking objects:  16% (10/62)   \r",
      "Unpacking objects:  17% (11/62)   \r",
      "Unpacking objects:  19% (12/62)   \r",
      "Unpacking objects:  20% (13/62)   \r",
      "Unpacking objects:  22% (14/62)   \r",
      "Unpacking objects:  24% (15/62)   \r",
      "Unpacking objects:  25% (16/62)   \r",
      "Unpacking objects:  27% (17/62)   \r",
      "Unpacking objects:  29% (18/62)   \r",
      "Unpacking objects:  30% (19/62)   \r",
      "Unpacking objects:  32% (20/62)   \r",
      "Unpacking objects:  33% (21/62)   \r",
      "Unpacking objects:  35% (22/62)   \r",
      "Unpacking objects:  37% (23/62)   \r",
      "Unpacking objects:  38% (24/62)   \r",
      "Unpacking objects:  40% (25/62)   \r",
      "Unpacking objects:  41% (26/62)   \r",
      "remote: Total 62 (delta 31), reused 40 (delta 15), pack-reused 0\u001b[K\n",
      "Unpacking objects:  43% (27/62)   \r",
      "Unpacking objects:  45% (28/62)   \r",
      "Unpacking objects:  46% (29/62)   \r",
      "Unpacking objects:  48% (30/62)   \r",
      "Unpacking objects:  50% (31/62)   \r",
      "Unpacking objects:  51% (32/62)   \r",
      "Unpacking objects:  53% (33/62)   \r",
      "Unpacking objects:  54% (34/62)   \r",
      "Unpacking objects:  56% (35/62)   \r",
      "Unpacking objects:  58% (36/62)   \r",
      "Unpacking objects:  59% (37/62)   \r",
      "Unpacking objects:  61% (38/62)   \r",
      "Unpacking objects:  62% (39/62)   \r",
      "Unpacking objects:  64% (40/62)   \r",
      "Unpacking objects:  66% (41/62)   \r",
      "Unpacking objects:  67% (42/62)   \r",
      "Unpacking objects:  69% (43/62)   \r",
      "Unpacking objects:  70% (44/62)   \r",
      "Unpacking objects:  72% (45/62)   \r",
      "Unpacking objects:  74% (46/62)   \r",
      "Unpacking objects:  75% (47/62)   \r",
      "Unpacking objects:  77% (48/62)   \r",
      "Unpacking objects:  79% (49/62)   \r",
      "Unpacking objects:  80% (50/62)   \r",
      "Unpacking objects:  82% (51/62)   \r",
      "Unpacking objects:  83% (52/62)   \r",
      "Unpacking objects:  85% (53/62)   \r",
      "Unpacking objects:  87% (54/62)   \r",
      "Unpacking objects:  88% (55/62)   \r",
      "Unpacking objects:  90% (56/62)   \r",
      "Unpacking objects:  91% (57/62)   \r",
      "Unpacking objects:  93% (58/62)   \r",
      "Unpacking objects:  95% (59/62)   \r",
      "Unpacking objects:  96% (60/62)   \r",
      "Unpacking objects:  98% (61/62)   \r",
      "Unpacking objects: 100% (62/62)   \r",
      "Unpacking objects: 100% (62/62), done.\n",
      "Submodule 'Chatbot_data' (https://github.com/haven-jeon/Chatbot_data.git) registered for path 'Chatbot_data'\n",
      "Cloning into '/content/KoGPT2-chatbot/Chatbot_data'...\n",
      "remote: Enumerating objects: 20, done.        \n",
      "remote: Total 20 (delta 0), reused 0 (delta 0), pack-reused 20        \n",
      "Submodule path 'Chatbot_data': checked out '235fac5aea3badab22743f7048afe936cf72f822'\n"
     ]
    }
   ],
   "source": [
    "# KoGPT2-chatbot 소스 코드 복사\n",
    "!git clone --recurse-submodules https://github.com/haven-jeon/KoGPT2-chatbot.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "e9ZweKmXiuaK",
    "outputId": "6cc6ce8b-105b-4f39-b865-22508865cf6c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/KoGPT2-chatbot\n"
     ]
    }
   ],
   "source": [
    "# 폴더 이동\n",
    "%cd KoGPT2-chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 732
    },
    "colab_type": "code",
    "id": "xKMZv-ZsiqkB",
    "outputId": "7cf55491-8fbd-4201-a849-9616b638d3d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-25 10:56:43.124599: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "[██████████████████████████████████████████████████]\n",
      "[██████████████████████████████████████████████████]\n",
      "using cached model\n",
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type             | Params\n",
      "---------------------------------------------------\n",
      "0 | kogpt2        | GPT2LMHeadModel  | 124 M \n",
      "1 | loss_function | CrossEntropyLoss | 0     \n",
      "/usr/local/lib/python3.6/dist-packages/pytorch_lightning/utilities/distributed.py:25: UserWarning: The dataloader, train dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 2 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  warnings.warn(*args, **kwargs)\n",
      "Epoch 1:   0% 0/185 [00:00<?, ?it/s] INFO:root:contexts : 다가온 이별\n",
      "INFO:root:toked ctx: ['<usr>', '▁다가온', '▁이별', '</s>', '<unused1>', '▁1', '</s>']\n",
      "INFO:root:response : 이별 예약제.\n",
      "INFO:root:contexts : 행복하기 위해 중요한 게 뭐야?\n",
      "INFO:root:toked response : ['<sys>', '▁이별', '▁예약', '제', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁이별', '▁예약', '제', '.', '</s>']\n",
      "INFO:root:toked ctx: ['<usr>', '▁행복', '하기', '▁위해', '▁중요한', '▁게', '▁뭐', '야', '?', '</s>', '<unused1>', '▁0', '</s>']\n",
      "INFO:root:response : 인생을 즐기는 거죠.\n",
      "INFO:root:toked response : ['<sys>', '▁인생을', '▁즐기는', '▁거죠', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁인생을', '▁즐기는', '▁거죠', '.', '</s>']\n",
      "Epoch 1: 100% 185/185 [03:54<00:00,  1.27s/it, loss=2.400, v_num=0]\n",
      "Epoch 00001: loss reached 2.51730 (best 2.51730), saving model to /content/KoGPT2-chatbot/model_chp/model_epoch=01-loss=2.52.ckpt as top 1\n",
      "Epoch 2:   0% 0/185 [00:00<?, ?it/s, loss=2.400, v_num=0]INFO:root:contexts : 사랑하는 사람은 딱 알아볼 수 있어?\n",
      "INFO:root:toked ctx: ['<usr>', '▁사랑하는', '▁사람은', '▁딱', '▁알아볼', '▁수', '▁있어', '?', '</s>', '<unused1>', '▁2', '</s>']\n",
      "INFO:root:response : 감정은 감출수 있는게 아니에요.\n",
      "INFO:root:toked response : ['<sys>', '▁감', '정은', '▁감', '출', '수', '▁있는', '게', '▁아니', '에요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁감', '정은', '▁감', '출', '수', '▁있는', '게', '▁아니', '에요', '.', '</s>']\n",
      "INFO:root:contexts : 이미 잘못이 너무 많아서.\n",
      "INFO:root:toked ctx: ['<usr>', '▁이미', '▁잘못', '이', '▁너무', '▁많아서', '.', '</s>', '<unused1>', '▁1', '</s>']\n",
      "INFO:root:response : 더 이상의 잘못은 이해하지 못할 거예요.\n",
      "INFO:root:toked response : ['<sys>', '▁더', '▁이상의', '▁잘못', '은', '▁이해하지', '▁못할', '▁거예요', '.', '</s>']\n",
      "INFO:root:labels ['<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '<unused0>', '▁더', '▁이상의', '▁잘못', '은', '▁이해하지', '▁못할', '▁거예요', '.', '</s>']\n",
      "Epoch 2: 100% 185/185 [03:58<00:00,  1.29s/it, loss=2.078, v_num=0]\n",
      "Epoch 00002: loss reached 2.17900 (best 2.17900), saving model to /content/KoGPT2-chatbot/model_chp/model_epoch=02-loss=2.18.ckpt as top 1\n",
      "Epoch 2: 100% 185/185 [04:42<00:00,  1.52s/it, loss=2.078, v_num=0]\n",
      "INFO:root:best model path /content/KoGPT2-chatbot/model_chp/model_epoch=02-loss=2.18.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 사전훈련된 KoGPT2를 챗봇 데이터로 파인튜닝\n",
    "!CUDA_VISIBLE_DEVICES=0 python train_torch.py --train --gpus 1 --max_epochs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "f3yDcidi6wFA",
    "outputId": "b66e761c-3731-4f82-ce8b-411a65a7363d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-06-25 11:07:27.562722: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "using cached model\n",
      "user > 집이 너무 비싸네.\n",
      "Simsimi > 집 없는 설움을 겪으셨나봐요.\n",
      "user > 아침에 잠이 너무 많아서 걱정이야.\n",
      "Simsimi > 잠이 안 올 거예요.\n",
      "user > 비도 많이 오고 너무 더워.\n",
      "Simsimi > 시원한 음료 드세요.\n",
      "user > 비오는데 우산을 안가져 왔네..\n",
      "Simsimi > 우산 챙기세요.\n",
      "user > 비가 너무 많이와\n",
      "Simsimi > 우산 챙기세요.\n",
      "user > quit\n"
     ]
    }
   ],
   "source": [
    "# 대화 테스트, `quit`를 입력하면 대화를 종료합니다.\n",
    "!CUDA_VISIBLE_DEVICES=0 python train_torch.py --gpus 1 --chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QoeGog7OoXFk"
   },
   "source": [
    "이 노트북은   https://colab.research.google.com/drive/1Np7d8zrch589LwwW9oX_MyzJ9jfPEvUG?usp=sharing  를 수정하여 만들었습니다..  "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "KoGPT2_chatbot_pytorch",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
